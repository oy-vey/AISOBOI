{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Параметры\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "TRAINING_ITERATIONS = 20000        \n",
    "    \n",
    "DROPOUT = 0.5\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "VALIDATION_SIZE = 2000\n",
    "\n",
    "IMAGE_TO_DISPLAY = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data(42000,785)\n",
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "0       0    ...            0         0         0         0         0   \n",
      "1       0    ...            0         0         0         0         0   \n",
      "2       0    ...            0         0         0         0         0   \n",
      "3       0    ...            0         0         0         0         0   \n",
      "4       0    ...            0         0         0         0         0   \n",
      "\n",
      "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0         0  \n",
      "1         0         0         0         0         0  \n",
      "2         0         0         0         0         0  \n",
      "3         0         0         0         0         0  \n",
      "4         0         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./train.csv')\n",
    "\n",
    "print('data({0[0]},{0[1]})'.format(data.shape))\n",
    "print (data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images(42000,784)\n"
     ]
    }
   ],
   "source": [
    "images = data.iloc[:,1:].values\n",
    "images = images.astype(np.float)\n",
    "\n",
    "# Нормализация\n",
    "images = np.multiply(images, 1.0 / 255.0)\n",
    "\n",
    "print('images({0[0]},{0[1]})'.format(images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size => 784\n",
      "image_width => 28\n",
      "image_height => 28\n"
     ]
    }
   ],
   "source": [
    "image_size = images.shape[1]\n",
    "print ('image_size => {0}'.format(image_size))\n",
    "\n",
    "image_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8)\n",
    "\n",
    "print ('image_width => {0}\\nimage_height => {1}'.format(image_width,image_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121ac03c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Пример изображения \n",
    "def display(img):\n",
    "    \n",
    "    # (784) => (28,28)\n",
    "    one_image = img.reshape(image_width,image_height)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.imshow(one_image, cmap=cm.binary)\n",
    "\n",
    "     \n",
    "display(images[IMAGE_TO_DISPLAY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_flat(42000)\n",
      "labels_flat[10] => 8\n"
     ]
    }
   ],
   "source": [
    "labels_flat = data[[0]].values.ravel()\n",
    "\n",
    "print('labels_flat({0})'.format(len(labels_flat)))\n",
    "print ('labels_flat[{0}] => {1}'.format(IMAGE_TO_DISPLAY,labels_flat[IMAGE_TO_DISPLAY]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_count => 10\n"
     ]
    }
   ],
   "source": [
    "labels_count = np.unique(labels_flat).shape[0]\n",
    "\n",
    "print('labels_count => {0}'.format(labels_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels(42000,10)\n",
      "labels[10] => [0 0 0 0 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# 0 => [1 0 0 0 0 0 0 0 0 0]\n",
    "# 1 => [0 1 0 0 0 0 0 0 0 0]\n",
    "# ...\n",
    "# 9 => [0 0 0 0 0 0 0 0 0 1]\n",
    "def dense_to_one_hot(labels_dense, num_classes):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "labels = dense_to_one_hot(labels_flat, labels_count)\n",
    "labels = labels.astype(np.uint8)\n",
    "\n",
    "print('labels({0[0]},{0[1]})'.format(labels.shape))\n",
    "print ('labels[{0}] => {1}'.format(IMAGE_TO_DISPLAY,labels[IMAGE_TO_DISPLAY]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images(40000,784)\n",
      "validation_images(2000,784)\n"
     ]
    }
   ],
   "source": [
    "# Разделение на выборки на обучающую и валидационную\n",
    "validation_images = images[:VALIDATION_SIZE]\n",
    "validation_labels = labels[:VALIDATION_SIZE]\n",
    "\n",
    "train_images = images[VALIDATION_SIZE:]\n",
    "train_labels = labels[VALIDATION_SIZE:]\n",
    "\n",
    "\n",
    "print('train_images({0[0]},{0[1]})'.format(train_images.shape))\n",
    "print('validation_images({0[0]},{0[1]})'.format(validation_images.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Определение архитектуры нейронной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Сверточных слоя с 32-мя и 64-мя фильтрами соответственно, 2 полносвязанных слоя, размером с output-ом 1024 и 10 соответсвенно. После каждой свертки выполняется операция субдискретизации (уменьшениия размерности в 2 раза)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вспомогательные функции для создания новых TensorFlow переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вспомогательные функции для создания новых сверточных слоев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, # Предыдущий слой (входные данные)\n",
    "                        W, # Веса\n",
    "                        strides=[1, 1, 1, 1], # Шаг для ImageID, X, Y, input-chanenl \n",
    "                        padding='SAME') # size(Input) = size(Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pooling\n",
    "# [[0,3],\n",
    "#  [4,2]] => 4\n",
    "\n",
    "# [[0,1],\n",
    "#  [1,1]] => 1\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Входные и выходные данные для НС\n",
    "\n",
    "# Изображение\n",
    "x = tf.placeholder('float', shape=[None, image_size])\n",
    "# Класс\n",
    "y_ = tf.placeholder('float', shape=[None, labels_count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Первый сверточный слой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Первый сверточный слой\n",
    "W_conv1 = weight_variable([5, 5, 1, 32]) # filter height, filter width, number of input channels, number of filters.  \n",
    "b_conv1 = bias_variable([32]) # One bias for each filter\n",
    "\n",
    "# (40000,784) => (40000,28,28,1)\n",
    "image = tf.reshape(x, [-1,image_width , image_height,1])\n",
    "#print (image.get_shape()) # =>(40000,28,28,1)\n",
    "\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(image, W_conv1) + b_conv1) # Add biases to the result of convolution\n",
    "#print (h_conv1.get_shape()) # => (40000, 28, 28, 32)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "#print (h_pool1.get_shape()) # => (40000, 14, 14, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Второй сверточный слой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "#print (h_conv2.get_shape()) # => (40000, 14,14, 64)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "#print (h_pool2.get_shape()) # => (40000, 7, 7, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Первый полносвязанный слой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "# (40000, 7, 7, 64) => (40000, 3136)\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "#print (h_fc1.get_shape()) # => (40000, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку полносвязный слой подвержен переобучению, для предотвращеня этой проблемы будем использовать метод dropout, который с вероятностью 1 - keep_prob будет \"выбрасывать\" из сети ноды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dropout\n",
    "keep_prob = tf.placeholder('float')\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Второй (финальный) полносвязанный слой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй полносвязный слой оценивает насколько входное изображение подходит под каждый из 10 классов. Перед этим мы нормализуем результат таким образо, что значения в выходном векторе находятся в диапазоне от 0 до 1 и в сумме дают 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, labels_count])\n",
    "b_fc2 = bias_variable([labels_count])\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "#print (y.get_shape()) # => (40000, 10)\n",
    "\n",
    "predict = tf.argmax(y,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция потерь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для измерения качества модели мы должны оценивать ошибку сравнивая прогнозные и реальные значения. Перекрёстная энтропия -функция, которая принимает только неотрицательные значения и равна 0 в случае совпадения прогноза и реальности. Следовательно, целью оптимизации является минимизация перекрёстной энтропии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "\n",
    "# Аналог градиентного спуска\n",
    "train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка точности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конвертим boolean в float  и находим среднее значение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция разбиения выборки на пачки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимальным вариантом было бы использование всего датасета на каждой итерации обучения, однако это слишком ресурсоемко. Вместо этого будем использовать маленькие случайные \"пачки\" данных. Этот метод называется стохастическое обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs_completed = 0\n",
    "index_in_epoch = 0\n",
    "num_examples = train_images.shape[0]\n",
    "\n",
    "# serve data by batches\n",
    "def next_batch(batch_size):\n",
    "    \n",
    "    global train_images\n",
    "    global train_labels\n",
    "    global index_in_epoch\n",
    "    global epochs_completed\n",
    "    \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    # when all trainig data have been already used, it is reorder randomly    \n",
    "    if index_in_epoch > num_examples:\n",
    "        # finished epoch\n",
    "        epochs_completed += 1\n",
    "        # shuffle the data\n",
    "        perm = np.arange(num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        train_images = train_images[perm]\n",
    "        train_labels = train_labels[perm]\n",
    "        # start next epoch\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "        assert batch_size <= num_examples\n",
    "    end = index_in_epoch\n",
    "    return train_images[start:end], train_labels[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Тренировка сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Открытие TensorFlow сессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-22-2c1d895c5572>:1: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy / validation_accuracy => 0.16 / 0.12 for step 0\n",
      "training_accuracy / validation_accuracy => 0.10 / 0.12 for step 1\n",
      "training_accuracy / validation_accuracy => 0.18 / 0.16 for step 2\n",
      "training_accuracy / validation_accuracy => 0.14 / 0.18 for step 3\n",
      "training_accuracy / validation_accuracy => 0.20 / 0.14 for step 4\n",
      "training_accuracy / validation_accuracy => 0.20 / 0.24 for step 5\n",
      "training_accuracy / validation_accuracy => 0.32 / 0.26 for step 6\n",
      "training_accuracy / validation_accuracy => 0.38 / 0.28 for step 7\n",
      "training_accuracy / validation_accuracy => 0.18 / 0.28 for step 8\n",
      "training_accuracy / validation_accuracy => 0.28 / 0.30 for step 9\n",
      "training_accuracy / validation_accuracy => 0.24 / 0.28 for step 10\n",
      "training_accuracy / validation_accuracy => 0.46 / 0.58 for step 20\n",
      "training_accuracy / validation_accuracy => 0.52 / 0.56 for step 30\n",
      "training_accuracy / validation_accuracy => 0.78 / 0.74 for step 40\n",
      "training_accuracy / validation_accuracy => 0.66 / 0.78 for step 50\n",
      "training_accuracy / validation_accuracy => 0.74 / 0.76 for step 60\n",
      "training_accuracy / validation_accuracy => 0.90 / 0.86 for step 70\n",
      "training_accuracy / validation_accuracy => 0.88 / 0.88 for step 80\n",
      "training_accuracy / validation_accuracy => 0.88 / 0.88 for step 90\n",
      "training_accuracy / validation_accuracy => 0.92 / 0.86 for step 100\n",
      "training_accuracy / validation_accuracy => 0.92 / 0.88 for step 200\n",
      "training_accuracy / validation_accuracy => 0.94 / 0.92 for step 300\n",
      "training_accuracy / validation_accuracy => 0.94 / 0.96 for step 400\n",
      "training_accuracy / validation_accuracy => 0.98 / 0.96 for step 500\n",
      "training_accuracy / validation_accuracy => 0.96 / 0.96 for step 600\n",
      "training_accuracy / validation_accuracy => 0.92 / 0.96 for step 700\n",
      "training_accuracy / validation_accuracy => 0.96 / 0.96 for step 800\n",
      "training_accuracy / validation_accuracy => 0.98 / 0.96 for step 900\n",
      "training_accuracy / validation_accuracy => 0.96 / 0.96 for step 1000\n",
      "training_accuracy / validation_accuracy => 0.98 / 0.96 for step 2000\n",
      "training_accuracy / validation_accuracy => 1.00 / 0.96 for step 3000\n",
      "training_accuracy / validation_accuracy => 1.00 / 0.98 for step 4000\n",
      "training_accuracy / validation_accuracy => 0.98 / 0.96 for step 5000\n",
      "training_accuracy / validation_accuracy => 1.00 / 1.00 for step 6000\n",
      "training_accuracy / validation_accuracy => 1.00 / 0.98 for step 7000\n",
      "training_accuracy / validation_accuracy => 1.00 / 1.00 for step 8000\n",
      "training_accuracy / validation_accuracy => 1.00 / 1.00 for step 9000\n",
      "training_accuracy / validation_accuracy => 0.96 / 1.00 for step 10000\n",
      "training_accuracy / validation_accuracy => 1.00 / 1.00 for step 19999\n"
     ]
    }
   ],
   "source": [
    "# visualisation variables\n",
    "train_accuracies = []\n",
    "validation_accuracies = []\n",
    "x_range = []\n",
    "\n",
    "display_step=1\n",
    "\n",
    "for i in range(TRAINING_ITERATIONS):\n",
    "\n",
    "    #get new batch\n",
    "    batch_xs, batch_ys = next_batch(BATCH_SIZE)        \n",
    "\n",
    "    # check progress on every 1st,2nd,...,10th,20th,...,100th... step\n",
    "    if i%display_step == 0 or (i+1) == TRAINING_ITERATIONS:\n",
    "        \n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch_xs, \n",
    "                                                  y_: batch_ys, \n",
    "                                                  keep_prob: 1.0})       \n",
    "        if(VALIDATION_SIZE):\n",
    "            validation_accuracy = accuracy.eval(feed_dict={ x: validation_images[0:BATCH_SIZE], \n",
    "                                                            y_: validation_labels[0:BATCH_SIZE], \n",
    "                                                            keep_prob: 1.0})                                  \n",
    "            print('training_accuracy / validation_accuracy => %.2f / %.2f for step %d'%(train_accuracy, validation_accuracy, i))\n",
    "            \n",
    "            validation_accuracies.append(validation_accuracy)\n",
    "            \n",
    "        else:\n",
    "             print('training_accuracy => %.4f for step %d'%(train_accuracy, i))\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        x_range.append(i)\n",
    "        \n",
    "        # increase display_step\n",
    "        if i%(display_step*10) == 0 and i:\n",
    "            display_step *= 10\n",
    "    # train on batch\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys, keep_prob: DROPOUT})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем точность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_accuracy => 0.9950\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114678e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if(VALIDATION_SIZE):\n",
    "    validation_accuracy = accuracy.eval(feed_dict={x: validation_images, \n",
    "                                                   y_: validation_labels, \n",
    "                                                   keep_prob: 1.0})\n",
    "    print('validation_accuracy => %.4f'%validation_accuracy)\n",
    "    plt.plot(x_range, train_accuracies,'-b', label='Training')\n",
    "    plt.plot(x_range, validation_accuracies,'-g', label='Validation')\n",
    "    plt.legend(loc='lower right', frameon=False)\n",
    "    plt.ylim(ymax = 1.1, ymin = 0.7)\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('step')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Отработка модели на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_images(28000,784)\n",
      "predicted_lables(28000)\n",
      "predicted_lables[10] => 5.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120db4780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_images = pd.read_csv('./test.csv').values\n",
    "test_images = test_images.astype(np.float)\n",
    "\n",
    "# нормализация\n",
    "test_images = np.multiply(test_images, 1.0 / 255.0)\n",
    "\n",
    "print('test_images({0[0]},{0[1]})'.format(test_images.shape))\n",
    "\n",
    "\n",
    "predicted_lables = np.zeros(test_images.shape[0])\n",
    "for i in range(0,test_images.shape[0]//BATCH_SIZE):\n",
    "    predicted_lables[i*BATCH_SIZE : (i+1)*BATCH_SIZE] = predict.eval(feed_dict={x: test_images[i*BATCH_SIZE : (i+1)*BATCH_SIZE], \n",
    "                                                                                keep_prob: 1.0})\n",
    "\n",
    "\n",
    "print('predicted_lables({0})'.format(len(predicted_lables)))\n",
    "\n",
    "\n",
    "display(test_images[IMAGE_TO_DISPLAY])\n",
    "print ('predicted_lables[{0}] => {1}'.format(IMAGE_TO_DISPLAY,predicted_lables[IMAGE_TO_DISPLAY]))\n",
    "\n",
    "# Сохранение результата\n",
    "np.savetxt('submission.csv', \n",
    "           np.c_[range(1,len(test_images)+1),predicted_lables], \n",
    "           delimiter=',', \n",
    "           header = 'ImageId,Label', \n",
    "           comments = '', \n",
    "           fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
